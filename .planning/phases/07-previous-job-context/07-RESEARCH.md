# Phase 7: Previous Job Context - Research

**Researched:** 2026-02-25
**Domain:** SQLite persistence, Drizzle ORM migrations, job prompt enrichment
**Confidence:** HIGH

---

## Summary

Phase 7 closes the follow-up loop: when a user sends a second message in the same Slack/Telegram/web thread after a prior job completes, the new job description includes a human-readable summary of what the previous job accomplished — what it changed, where the PR landed, and what the agent did. Without this, every job starts blind and the agent re-discovers repo state from scratch.

The implementation has three clean integration points in the existing codebase. First, `handleGithubWebhook` in `api/index.js` already receives every field needed (job task, changed files, PR URL, merge result, log summary) — it just needs to persist a `job_outcomes` row after summarising, instead of discarding that data. Second, the `createJobTool` in `lib/ai/tools.js` already has access to the `thread_id` and constructs the `job_description` string — it needs to look up the prior outcome for that thread and prepend a summary block. Third, Drizzle ORM with better-sqlite3 is the established DB layer — adding a new table follows the exact same pattern as `job_origins` (schema entry + `npm run db:generate` + a new `lib/db/job-outcomes.js` helper file).

The critical gating requirement (HIST-03) is that prior context injection is only enabled when `merge_result === "merged"`. This is already a field in the webhook payload. A non-merged PR means the agent's work was rejected or is under review — injecting it as "what happened last time" would mislead the next agent run.

**Primary recommendation:** Add `job_outcomes` table via Drizzle migration, persist on webhook receipt, look up by `thread_id` inside `createJobTool`, and gate injection on `merge_result === "merged"`.

---

<phase_requirements>
## Phase Requirements

| ID | Description | Research Support |
|----|-------------|-----------------|
| HIST-01 | `job_outcomes` table persists job completion data (status, changed files, PR URL, log summary) on webhook receipt | New Drizzle table + insert inside `handleGithubWebhook` after `summarizeJob` completes |
| HIST-02 | Follow-up job descriptions include prior job summary when the previous PR on the same thread was merged | `createJobTool` looks up latest `job_outcomes` row by `thread_id`, prepends summary block to `job_description` |
| HIST-03 | Previous job context injection is gated on `merge_result == "merged"` | Lookup returns `null` when `merge_result !== "merged"`; or filter at query level; summary block simply not added |
| HIST-04 | Previous job context lookups are scoped by `thread_id` for instance isolation | All queries include `eq(jobOutcomes.threadId, threadId)` — same isolation pattern as `job_origins` |
</phase_requirements>

---

## Standard Stack

### Core (already in use — no new installs)

| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| `drizzle-orm` | `^0.44.0` | Schema definition, query builder, migration runner | Already the project DB layer; `getDb()` singleton in `lib/db/index.js` |
| `better-sqlite3` | (peer dep) | SQLite driver | Already wired; WAL mode enabled at startup |
| `drizzle-kit` | `^0.31.9` | Migration file generation | `npm run db:generate` already configured |

### No new dependencies required

All libraries needed for Phase 7 are already installed. The pattern is purely:
1. Add table definition to `lib/db/schema.js`
2. Run `npm run db:generate` to produce the SQL migration file
3. Add `lib/db/job-outcomes.js` helper (mirrors `lib/db/job-origins.js` pattern)
4. Wire into two existing call sites: `handleGithubWebhook` and `createJobTool`

**Installation:**
```bash
# Nothing to install — use existing drizzle-orm + better-sqlite3
npm run db:generate  # generates the migration file after schema edit
```

---

## Architecture Patterns

### Recommended File Layout (additions only)

```
lib/db/
├── schema.js          # Add jobOutcomes table definition here
├── job-origins.js     # Existing — reference pattern
├── job-outcomes.js    # NEW — saveJobOutcome(), getLastJobOutcome()
api/
└── index.js           # Edit handleGithubWebhook — add saveJobOutcome() call
lib/ai/
└── tools.js           # Edit createJobTool — add prior context lookup + injection
drizzle/
└── 0002_*.sql         # Generated by db:generate — do not hand-write
```

### Pattern 1: Drizzle Table Definition (from existing codebase)

The `job_origins` table is the direct model for `job_outcomes`. Use the same integer timestamps and text fields pattern:

```javascript
// lib/db/schema.js — add alongside existing tables
export const jobOutcomes = sqliteTable('job_outcomes', {
  id: text('id').primaryKey(),              // randomUUID()
  jobId: text('job_id').notNull(),          // UUID from webhook payload
  threadId: text('thread_id').notNull(),    // from job_origins lookup
  status: text('status').notNull(),         // "completed" | "OPEN" | etc.
  mergeResult: text('merge_result').notNull(), // "merged" | "not_merged"
  prUrl: text('pr_url').notNull().default(''),
  changedFiles: text('changed_files').notNull().default(''), // JSON array as text
  logSummary: text('log_summary').notNull().default(''),     // output of summarizeJob()
  createdAt: integer('created_at').notNull(),
});
```

### Pattern 2: DB Helper Module (from existing codebase)

`lib/db/job-origins.js` is the exact template to follow:

```javascript
// lib/db/job-outcomes.js
import { randomUUID } from 'crypto';
import { eq, desc } from 'drizzle-orm';
import { getDb } from './index.js';
import { jobOutcomes } from './schema.js';

/**
 * Persist outcome data for a completed job.
 */
export function saveJobOutcome({ jobId, threadId, status, mergeResult, prUrl, changedFiles, logSummary }) {
  const db = getDb();
  db.insert(jobOutcomes)
    .values({
      id: randomUUID(),
      jobId,
      threadId,
      status,
      mergeResult,
      prUrl: prUrl || '',
      changedFiles: JSON.stringify(changedFiles || []),
      logSummary: logSummary || '',
      createdAt: Date.now(),
    })
    .run();
}

/**
 * Look up the most recent completed job for a thread where the PR was merged.
 * Returns null if no merged outcome exists — caller skips context injection.
 */
export function getLastMergedJobOutcome(threadId) {
  const db = getDb();
  return db
    .select()
    .from(jobOutcomes)
    .where(eq(jobOutcomes.threadId, threadId))
    .orderBy(desc(jobOutcomes.createdAt))
    .limit(1)
    .get() ?? null;
}
```

### Pattern 3: Webhook Handler Integration

`handleGithubWebhook` in `api/index.js` already calls `summarizeJob(results)` and `getJobOrigin(jobId)`. Add `saveJobOutcome` after both:

```javascript
// api/index.js — inside handleGithubWebhook, after existing code
import { saveJobOutcome } from '../lib/db/job-outcomes.js';

// ...existing code: summarizeJob, createNotification, getJobOrigin...
const origin = getJobOrigin(jobId);
if (origin) {
  // NEW — persist outcome for future jobs in this thread
  try {
    saveJobOutcome({
      jobId,
      threadId: origin.threadId,
      status: results.status,
      mergeResult: results.merge_result,
      prUrl: results.pr_url,
      changedFiles: results.changed_files,
      logSummary: message,  // message = await summarizeJob(results)
    });
  } catch (err) {
    console.error('Failed to save job outcome:', err);
  }

  // ...existing addToThread, Slack notification...
}
```

### Pattern 4: createJobTool Prior Context Injection

The `createJobTool` already constructs `job_description` and has access to `thread_id` from `config?.configurable?.thread_id`. The lookup and injection happen before `createJob(job_description)` is called:

```javascript
// lib/ai/tools.js — inside createJobTool handler
import { getLastMergedJobOutcome } from '../db/job-outcomes.js';

const createJobTool = tool(
  async ({ job_description }, config) => {
    const threadId = config?.configurable?.thread_id;

    // Enrich job_description with prior job context if a merged outcome exists
    let enrichedDescription = job_description;
    if (threadId) {
      try {
        const prior = getLastMergedJobOutcome(threadId);
        if (prior && prior.mergeResult === 'merged') {
          const changedFiles = JSON.parse(prior.changedFiles || '[]');
          const priorContext = [
            '## Prior Job Context',
            '',
            `**Previous PR:** ${prior.prUrl || '(no URL)'}`,
            `**Status:** ${prior.status} (${prior.mergeResult})`,
            changedFiles.length ? `**Files changed:** ${changedFiles.join(', ')}` : '',
            prior.logSummary ? `**What happened:** ${prior.logSummary}` : '',
          ].filter(Boolean).join('\n');

          enrichedDescription = `${priorContext}\n\n---\n\n${job_description}`;
        }
      } catch (err) {
        console.error('Failed to load prior job context:', err);
        // Non-fatal — proceed with original description
      }
    }

    const result = await createJob(enrichedDescription);
    // ...existing saveJobOrigin...
  }
);
```

### Pattern 5: Drizzle Migration Generation

After editing `schema.js`, regenerate the migration:

```bash
cd /Users/nwessel/Claude\ Code/Business/Products/clawforge
npm run db:generate
```

This produces `drizzle/0002_*.sql` automatically with the correct `CREATE TABLE` statement. The migration runs automatically at startup via `initDatabase()` in `lib/db/index.js` → `migrate()`.

**Do not hand-write migration SQL** — always use `db:generate` so the meta journal stays consistent.

### Anti-Patterns to Avoid

- **Scoping by `job_id` instead of `thread_id`**: The requirement (HIST-04) and STATE.md decision explicitly call for `thread_id` scoping. `job_id` is ephemeral; `thread_id` is the durable conversation identifier.
- **Cross-instance thread ID leakage**: Because each instance has its own SQLite database (`data/clawforge.sqlite` under its own project root), `thread_id` scoping is automatically instance-isolated — no additional filtering is required beyond the `threadId` equality check.
- **Injecting prior context when PR was not merged**: `merge_result === "not_merged"` means the job's changes were rejected or still pending. Adding those changes as "what happened" would cause the next job to proceed on a false premise. The query must filter for `mergeResult === 'merged'` OR the caller must check and skip injection.
- **Fetching ALL past outcomes**: Only the most recent merged outcome is relevant. Use `orderBy(desc(...)).limit(1)` — not a full history scan.
- **Storing changed_files as a raw array column**: SQLite has no array type. Store as `JSON.stringify(array)` in a `text` column and parse on read. This matches how the webhook payload's `changed_files` field is already a string-joined list in `changed_files` from the workflow.

---

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Schema migration | Custom SQL scripts | `npm run db:generate` + Drizzle migrate | Meta journal must stay in sync; hand-written SQL breaks the journal |
| DB connection | New `Database()` call | `getDb()` singleton from `lib/db/index.js` | WAL mode, lazy init, and singleton guarantee already handled |
| UUID generation | Custom ID scheme | `randomUUID()` from Node `crypto` | Already the pattern in `notifications.js` |
| Thread isolation | Separate DB files per instance | `thread_id` equality in query | Each instance already has separate `data/clawforge.sqlite` |

**Key insight:** This phase is entirely plumbing — no new architecture, no new libraries. Every pattern already exists in the codebase.

---

## Common Pitfalls

### Pitfall 1: Webhook Payload Field Names

**What goes wrong:** The webhook payload field names in `notify-pr-complete.yml` were a known risk item (STATE.md blocker). A wrong assumption about field names leads to `undefined` values stored in `job_outcomes`.

**Why it happens:** The workflow serializes fields as `job_id`, `merge_result`, `changed_files`, etc. The JS handler receives them via `payload.merge_result` etc. These are already correctly mapped in `handleGithubWebhook` (verified in `api/index.js` lines 257-264).

**How to avoid:** Cross-check the payload object keys in `handleGithubWebhook` before passing to `saveJobOutcome`. The current mapping is:
- `payload.status` → `results.status`
- `payload.merge_result` → `results.merge_result`
- `payload.pr_url` → `results.pr_url`
- `payload.changed_files` → `results.changed_files` (already an array after jq `split("\n")` in workflow)
- `summarizeJob(results)` return value → `logSummary`

**Warning signs:** `undefined` values written to the DB; `JSON.parse` errors on `changedFiles` field.

### Pitfall 2: `changed_files` Type Inconsistency

**What goes wrong:** The webhook workflow produces `changed_files` as an array (`split("\n") | map(select(length > 0))`). The JS handler receives it as `results.changed_files` — already an array. Storing `JSON.stringify([])` is correct. But if the field arrives as a newline-delimited string in some code path, `JSON.parse` on read would fail.

**How to avoid:** Always call `JSON.stringify(Array.isArray(changedFiles) ? changedFiles : [])` before insert. Always call `JSON.parse(prior.changedFiles || '[]')` before use.

### Pitfall 3: `getJobOrigin` Returns `undefined` for Jobs Without an Origin

**What goes wrong:** Not all jobs have a `job_origins` row (e.g., jobs created via `/api/create-job` directly without a thread). If `origin` is `undefined`, `saveJobOutcome` would fail or write a null `thread_id`.

**How to avoid:** Gate `saveJobOutcome` inside the `if (origin)` block — identical to how `addToThread` is already gated. This is already visible in the `handleGithubWebhook` structure.

### Pitfall 4: `createJobTool` Lookup Failure Must Not Block Job Creation

**What goes wrong:** If `getLastMergedJobOutcome` throws (DB locked, schema not yet migrated), the whole `create_job` call fails and the user's job never runs.

**How to avoid:** Wrap the lookup in `try/catch`, log the error, and fall back to the original `job_description`. Non-fatal. This pattern is already used for `saveJobOrigin` in the existing tool.

### Pitfall 5: Drizzle Meta Journal Out of Sync

**What goes wrong:** If someone hand-edits `drizzle/0002_*.sql` or creates it manually, the Drizzle meta journal (`_journal.json`) won't reflect it, causing `migrate()` to fail or re-run migrations.

**How to avoid:** Always use `npm run db:generate` after editing `schema.js`. Never hand-create migration files.

---

## Code Examples

### Table Definition (from existing pattern in schema.js)

```javascript
// Source: lib/db/schema.js (existing pattern)
import { sqliteTable, text, integer } from 'drizzle-orm/sqlite-core';

export const jobOutcomes = sqliteTable('job_outcomes', {
  id: text('id').primaryKey(),
  jobId: text('job_id').notNull(),
  threadId: text('thread_id').notNull(),
  status: text('status').notNull(),
  mergeResult: text('merge_result').notNull(),
  prUrl: text('pr_url').notNull().default(''),
  changedFiles: text('changed_files').notNull().default('[]'),
  logSummary: text('log_summary').notNull().default(''),
  createdAt: integer('created_at').notNull(),
});
```

### Query with Filter and Order (from existing pattern in notifications.js)

```javascript
// Source: lib/db/notifications.js (existing pattern — desc, orderBy, get)
import { eq, desc } from 'drizzle-orm';

export function getLastMergedJobOutcome(threadId) {
  const db = getDb();
  return db
    .select()
    .from(jobOutcomes)
    .where(eq(jobOutcomes.threadId, threadId))
    .orderBy(desc(jobOutcomes.createdAt))
    .limit(1)
    .get() ?? null;
}
```

### Sync Insert (from existing pattern in job-origins.js)

```javascript
// Source: lib/db/job-origins.js (existing pattern — sync .run())
export function saveJobOutcome({ jobId, threadId, status, mergeResult, prUrl, changedFiles, logSummary }) {
  const db = getDb();
  db.insert(jobOutcomes)
    .values({
      id: randomUUID(),
      jobId,
      threadId,
      status,
      mergeResult,
      prUrl: prUrl || '',
      changedFiles: JSON.stringify(Array.isArray(changedFiles) ? changedFiles : []),
      logSummary: logSummary || '',
      createdAt: Date.now(),
    })
    .run();
}
```

---

## State of the Art

| Old Approach | Current Approach | Notes |
|--------------|------------------|-------|
| Every job starts blind, re-discovers repo | Job description includes prior merged PR summary | Phase 7 change |
| `job_outcomes` doesn't exist | New table in SQLite via Drizzle migration | Phase 7 change |
| `createJobTool` passes raw `job_description` | `createJobTool` enriches description with prior context block | Phase 7 change |

**No deprecated patterns in scope** — this phase adds new functionality without replacing existing patterns.

---

## Open Questions

1. **Should `getLastMergedJobOutcome` return the most recent outcome regardless of merge status, and let the caller gate on `mergeResult`?**
   - What we know: HIST-03 says injection is gated on `merge_result === "merged"`. Either the query can filter by `mergeResult = 'merged'` directly, or the caller checks.
   - What's unclear: If filtering in query, there's no way to detect "there was a prior job but it wasn't merged" (which might be useful for a warning message). If filtering in caller, the query is simpler but requires null-check + field-check.
   - Recommendation: Filter in the query helper for simplicity (`where(and(eq(threadId,...), eq(mergeResult,'merged')))`). Success criteria only requires "does not include context when not merged" — no requirement for a warning message.

2. **Confirm `notify-pr-complete.yml` live workflow vs template are in sync**
   - What we know: Phase 5 requirement PIPE-05 verified byte-for-byte sync of workflow templates. STATE.md blocker notes "confirm webhook payload field names before generating Drizzle migration."
   - What's unclear: Whether a real webhook payload has been observed since Phase 5 testing.
   - Recommendation: Treat the template `notify-pr-complete.yml` as authoritative (it was synced in Phase 5). The field names (`job_id`, `status`, `merge_result`, `pr_url`, `changed_files`, `log`, `commit_message`) are confirmed correct from reading both the workflow and `handleGithubWebhook` in `api/index.js`.

3. **How long to retain `job_outcomes` rows?**
   - What we know: No requirements mention pruning.
   - What's unclear: At scale, old rows accumulate. For two instances with infrequent jobs, this is not a practical concern.
   - Recommendation: No retention policy in Phase 7. Add cleanup as a future enhancement if needed.

---

## Sources

### Primary (HIGH confidence)
- **Codebase direct read** — `lib/db/schema.js`, `lib/db/job-origins.js`, `lib/db/notifications.js`, `lib/db/index.js`, `lib/ai/tools.js`, `api/index.js`, `templates/.github/workflows/notify-pr-complete.yml` — all read and verified
- **`drizzle.config.js`** — confirms `db:generate` target is `./drizzle/`, dialect sqlite
- **`package.json` scripts** — confirms `npm run db:generate` invokes `drizzle-kit generate`
- **`drizzle/meta/_journal.json`** — confirms 2 existing migrations, next will be index 2
- **`.planning/STATE.md` decision** — "Phase 7 scopes all job_outcomes lookups by thread_id for instance isolation (not repo-scoped)" — locked

### Secondary (MEDIUM confidence)
- **WebSearch: drizzle-orm better-sqlite3 orderBy desc 2025** — confirmed `desc()` import from `drizzle-orm`, `.orderBy(desc(col))` pattern, consistent with codebase usage in `notifications.js`
- **`orm.drizzle.team/docs/select`** — standard Drizzle select/orderBy/limit patterns

### Tertiary (LOW confidence)
- None

---

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH — all libraries already in use, patterns already in codebase
- Architecture: HIGH — exact integration points identified, no ambiguity
- Pitfalls: HIGH — derived directly from codebase structure and STATE.md blocker notes

**Research date:** 2026-02-25
**Valid until:** 2026-03-25 (stable libraries, no fast-moving dependencies)
